{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Comparison of the different over-sampling algorithms\n",
    "\n",
    "\n",
    "The following example attends to make a qualitative comparison between the\n",
    "different over-sampling algorithms available in the imbalanced-learn package.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\n",
    "# License: MIT\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "from imblearn.base import SamplerMixin\n",
    "from imblearn.utils import hash_X_y\n",
    "\n",
    "print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be used to create toy dataset. It using the\n",
    "``make_classification`` from scikit-learn but fixing some parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n_samples=1000, weights=(0.01, 0.01, 0.98), n_classes=3,\n",
    "                   class_sep=0.8, n_clusters=1):\n",
    "    return make_classification(n_samples=n_samples, n_features=2,\n",
    "                               n_informative=2, n_redundant=0, n_repeated=0,\n",
    "                               n_classes=n_classes,\n",
    "                               n_clusters_per_class=n_clusters,\n",
    "                               weights=list(weights),\n",
    "                               class_sep=class_sep, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be used to plot the sample space after resampling\n",
    "to illustrate the characterisitic of an algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resampling(X, y, sampling, ax):\n",
    "    X_res, y_res = sampling.fit_sample(X, y)\n",
    "    ax.scatter(X_res[:, 0], X_res[:, 1], c=y_res, alpha=0.8, edgecolor='k')\n",
    "    # make nice plotting\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    return Counter(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be used to plot the decision function of a\n",
    "classifier given some data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_function(X, y, clf, ax):\n",
    "    plot_step = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.4)\n",
    "    ax.scatter(X[:, 0], X[:, 1], alpha=0.8, c=y, edgecolor='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustration of the influence of the balancing ratio\n",
    "##############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first illustrate the influence of the balancing ratio on some toy\n",
    "data using a linear SVM classifier. Greater is the difference between the\n",
    "number of samples in each class, poorer are the classfication results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "ax_arr = (ax1, ax2, ax3, ax4)\n",
    "weights_arr = ((0.01, 0.01, 0.98), (0.01, 0.05, 0.94),\n",
    "               (0.2, 0.1, 0.7), (0.33, 0.33, 0.33))\n",
    "for ax, weights in zip(ax_arr, weights_arr):\n",
    "    X, y = create_dataset(n_samples=1000, weights=weights)\n",
    "    clf = LinearSVC().fit(X, y)\n",
    "    plot_decision_function(X, y, clf, ax)\n",
    "    ax.set_title('Linear SVC with y={}'.format(Counter(y)))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random over-sampling to balance the data set\n",
    "##############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random over-sampling can be used to repeat some samples and balance the\n",
    "number of samples between the dataset. It can be seen that with this trivial\n",
    "approach the boundary decision is already less biaised toward the majority\n",
    "class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "X, y = create_dataset(n_samples=10000, weights=(0.01, 0.05, 0.94))\n",
    "clf = LinearSVC().fit(X, y)\n",
    "plot_decision_function(X, y, clf, ax1)\n",
    "ax1.set_title('Linear SVC with y={}'.format(Counter(y)))\n",
    "pipe = make_pipeline(RandomOverSampler(random_state=0), LinearSVC())\n",
    "pipe.fit(X, y)\n",
    "plot_decision_function(X, y, pipe, ax2)\n",
    "ax2.set_title('Decision function for RandomOverSampler')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced over-sampling using ADASYN and SMOTE\n",
    "##############################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of repeating the same samples when over-sampling, we can use some\n",
    "specific heuristic instead. ADASYN and SMOTE can be used in this case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an identity sampler\n",
    "class FakeSampler(SamplerMixin):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.ratio_ = 1\n",
    "        self.X_hash_ = hash_X_y(X, y)\n",
    "        return self\n",
    "\n",
    "    def sample(self, X, y):\n",
    "        return X,\n",
    "\n",
    "    def _sample(self, X, y):\n",
    "        pass\n",
    "\n",
    "    def fit_sample(self, X, y):\n",
    "        return X, y\n",
    "\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 15))\n",
    "X, y = create_dataset(n_samples=10000, weights=(0.01, 0.05, 0.94))\n",
    "sampler = FakeSampler()\n",
    "clf = make_pipeline(sampler, LinearSVC())\n",
    "plot_resampling(X, y, sampler, ax1)\n",
    "ax1.set_title('Original data - y={}'.format(Counter(y)))\n",
    "\n",
    "ax_arr = (ax2, ax3, ax4)\n",
    "for ax, sampler in zip(ax_arr, (RandomOverSampler(random_state=0),\n",
    "                                SMOTE(random_state=0),\n",
    "                                ADASYN(random_state=0))):\n",
    "    clf = make_pipeline(sampler, LinearSVC())\n",
    "    clf.fit(X, y)\n",
    "    plot_resampling(X, y, sampler, ax)\n",
    "    ax.set_title('Resampling using {}'.format(sampler.__class__.__name__))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot illustrate the difference between ADASYN and SMOTE. ADASYN\n",
    "will focus on the samples which are difficult to classify with a\n",
    "nearest-neighbors rule while regular SMOTE will not make any distinction.\n",
    "Therefore, the decision function depending of the algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 6))\n",
    "X, y = create_dataset(n_samples=10000, weights=(0.01, 0.05, 0.94))\n",
    "\n",
    "clf = LinearSVC().fit(X, y)\n",
    "plot_decision_function(X, y, clf, ax1)\n",
    "ax1.set_title('Linear SVC with y={}'.format(Counter(y)))\n",
    "sampler = SMOTE()\n",
    "clf = make_pipeline(sampler, LinearSVC())\n",
    "clf.fit(X, y)\n",
    "plot_decision_function(X, y, clf, ax2)\n",
    "ax2.set_title('Decision function for {}'.format(sampler.__class__.__name__))\n",
    "sampler = ADASYN()\n",
    "clf = make_pipeline(sampler, LinearSVC())\n",
    "clf.fit(X, y)\n",
    "plot_decision_function(X, y, clf, ax3)\n",
    "ax3.set_title('Decision function for {}'.format(sampler.__class__.__name__))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to those sampling particularities, it can give rise to some specific\n",
    "issues as illustrated below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 15))\n",
    "X, y = create_dataset(n_samples=5000, weights=(0.01, 0.05, 0.94),\n",
    "                      class_sep=0.8)\n",
    "\n",
    "ax_arr = ((ax1, ax2), (ax3, ax4))\n",
    "for ax, sampler in zip(ax_arr, (SMOTE(random_state=0),\n",
    "                                ADASYN(random_state=0))):\n",
    "    clf = make_pipeline(sampler, LinearSVC())\n",
    "    clf.fit(X, y)\n",
    "    plot_decision_function(X, y, clf, ax[0])\n",
    "    ax[0].set_title('Decision function for {}'.format(\n",
    "        sampler.__class__.__name__))\n",
    "    plot_resampling(X, y, sampler, ax[1])\n",
    "    ax[1].set_title('Resampling using {}'.format(\n",
    "        sampler.__class__.__name__))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE proposes several variants by identifying specific samples to consider\n",
    "during the resampling. The borderline version will detect which point to\n",
    "select which are in the border between two classes. The SVM version will use\n",
    "the support vectors found using an SVM algorithm to create new samples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4),\n",
    "      (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, figsize=(15, 30))\n",
    "X, y = create_dataset(n_samples=5000, weights=(0.01, 0.05, 0.94),\n",
    "                      class_sep=0.8)\n",
    "\n",
    "ax_arr = ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8))\n",
    "string_add = ['regular', 'borderline-1', 'borderline-2', 'SVM']\n",
    "for str_add, ax, sampler in zip(string_add,\n",
    "                                ax_arr,\n",
    "                                (SMOTE(random_state=0),\n",
    "                                 SMOTE(random_state=0, kind='borderline1'),\n",
    "                                 SMOTE(random_state=0, kind='borderline2'),\n",
    "                                 SMOTE(random_state=0, kind='svm'))):\n",
    "    clf = make_pipeline(sampler, LinearSVC())\n",
    "    clf.fit(X, y)\n",
    "    plot_decision_function(X, y, clf, ax[0])\n",
    "    ax[0].set_title('Decision function for {} {}'.format(\n",
    "        str_add, sampler.__class__.__name__))\n",
    "    plot_resampling(X, y, sampler, ax[1])\n",
    "    ax[1].set_title('Resampling using {} {}'.format(\n",
    "        str_add, sampler.__class__.__name__))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
